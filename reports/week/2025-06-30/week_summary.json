{
  "success": true,
  "date_range": {
    "start": "2025-06-30T00:00:00+00:00",
    "end": "2025-07-01T21:06:56.698202+00:00"
  },
  "summary": {
    "total_tickets": 2,
    "resolved_tickets": 0,
    "open_tickets": 2
  },
  "ticket_breakdown": [
    {
      "category": "bug",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "status:new",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "app:desktop application",
      "received": 2,
      "resolved": 0,
      "pending": 2
    },
    {
      "category": "os:linux",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "known_issue",
      "received": 1,
      "resolved": 0,
      "pending": 1
    }
  ],
  "most_active_tickets": [
    {
      "number": 315,
      "title": "Pieces desktop application is very slow/laggy, not generating any response in copilot chat.",
      "activity_level": 6.38
    },
    {
      "number": 537,
      "title": "Ollama Fails to Install on Linux",
      "activity_level": 4.92
    }
  ],
  "common_issues": [
    {
      "title": "Ollama installation failure and application slowness",
      "description": "Users reported issues with Ollama failing to install on Linux (v11) with an immediate error dialog.  Separately, slow performance and unresponsiveness were observed on Windows (v10) after a recent update, even after a hard reset. Both issues hinder core functionality.",
      "frequency": 2,
      "related_issues": [
        {
          "id": 537,
          "title": "Ollama Fails to Install on Linux",
          "text": "Ollama Fails to Install on Linux\n### Software\n\nDesktop Application\n\n### Operating System / Platform\n\nLinux\n\n### Your Pieces OS Version\n\n11.0.0\n\n### Early Access Program\n\n- [ ] Yes, this is related to an Early Access Program feature.\n\n### Kindly describe the bug and include as much detail as possible on what you were doing so we can reproduce the bug.\n\nUser reports immediate \"Ollama failed to install\" diaglog upon clicking install Ollama install button in Pieces desktop app\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 4.92
        },
        {
          "id": 315,
          "title": "Pieces desktop application is very slow/laggy, not generating any response in copilot chat.",
          "text": "Pieces desktop application is very slow/laggy, not generating any response in copilot chat.\n### Software\n\nDesktop Application\n\n### Operating System / Platform\n\nWindows\n\n### Your Pieces OS Version\n\n10.0.1\n\n### Early Access Program\n\n- [ ] Yes, this is related to an Early Access Program feature.\n\n### Kindly describe the bug and include as much detail as possible on what you were doing so we can reproduce the bug.\n\nPieces desktop application is working very much slow after latest update, takes very much time to give any response. Even after doing a hard reset active runtime, it just do not work. \nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 6.38
        }
      ]
    }
  ],
  "recommendations": [
    "Prioritize resolving the Ollama installation failure on Linux (v11) to unblock new users.",
    "Investigate and address the performance issues on Windows (v10) impacting core application responsiveness.",
    "Proactively monitor and address the known issue impacting both Linux and Windows users."
  ],
  "message": "Daily support report generated successfully."
}