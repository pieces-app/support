{
  "success": true,
  "date_range": {
    "start": "2025-06-16T00:00:00+00:00",
    "end": "2025-06-18T21:08:43.629074+00:00"
  },
  "summary": {
    "total_tickets": 9,
    "resolved_tickets": 0,
    "open_tickets": 9
  },
  "ticket_breakdown": [
    {
      "category": "bug",
      "received": 9,
      "resolved": 0,
      "pending": 9
    },
    {
      "category": "app:desktop application",
      "received": 7,
      "resolved": 0,
      "pending": 7
    },
    {
      "category": "os:macos",
      "received": 4,
      "resolved": 0,
      "pending": 4
    },
    {
      "category": "app:pieces cli",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "status:triaged",
      "received": 8,
      "resolved": 0,
      "pending": 8
    },
    {
      "category": "os:windows",
      "received": 2,
      "resolved": 0,
      "pending": 2
    },
    {
      "category": "status:new",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "app:pieces os",
      "received": 4,
      "resolved": 0,
      "pending": 4
    },
    {
      "category": "app:jetbrains",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "os:linux",
      "received": 2,
      "resolved": 0,
      "pending": 2
    },
    {
      "category": "app:vs code",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "app:jupyterlab",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "app:web extension",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "app:obsidian",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "app:visual studio",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "app:cli",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "app:neovim",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "app:sublime plugin",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "app:raycast plugin",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "maintenance_ongoing",
      "received": 4,
      "resolved": 0,
      "pending": 4
    },
    {
      "category": "provide_status_update_on_resolution",
      "received": 4,
      "resolved": 0,
      "pending": 4
    }
  ],
  "most_active_tickets": [
    {
      "number": 754,
      "title": "LTM-2.5 causes Chrome to freeze on large dynamic pages",
      "activity_level": 8.83
    },
    {
      "number": 751,
      "title": "Unable to generate Workstream Summary",
      "activity_level": 6.24
    },
    {
      "number": 755,
      "title": "Pieces has become increasingly slow and is now unresponsive",
      "activity_level": 5.6
    },
    {
      "number": 747,
      "title": "MCP `ask_pieces_ltm` tool consistently returns \"Failed to extract context\" despite functional LTM",
      "activity_level": 4.57
    },
    {
      "number": 758,
      "title": "Error Activating LTM-2.5 During Onboarding",
      "activity_level": 4.42
    },
    {
      "number": 753,
      "title": "Workstream activities tab is not working",
      "activity_level": 3.01
    },
    {
      "number": 752,
      "title": "Doesn't move past Initialising Desktop screen",
      "activity_level": 3.01
    },
    {
      "number": 459,
      "title": "Bug: unable to cancel the download of an LLLM",
      "activity_level": 2.65
    },
    {
      "number": 756,
      "title": "\ud83d\udea8 Ongoing Service Interruption Impacting Pieces Products and Cloud-Connected Features",
      "activity_level": 2.15
    }
  ],
  "common_issues": [
    {
      "title": "Pieces Fails to Access LTM Data via MCP",
      "description": "Users report the `ask_pieces_ltm` MCP tool consistently returns \"Failed to extract context\" despite functional LTM and successful communication with the MCP server.  Other MCP tools like `create_pieces_memory` work correctly.  The issue occurs across different clients and operating systems. Potential root causes include authentication issues, data access layer bugs, permissions problems, or initialization errors within the MCP server's interaction with the LTM data.",
      "frequency": 3,
      "related_issues": [
        {
          "id": 747,
          "title": "MCP `ask_pieces_ltm` tool consistently returns \"Failed to extract context\" despite functional LTM",
          "text": "MCP `ask_pieces_ltm` tool consistently returns \"Failed to extract context\" despite functional LTM\n### Checked for Existing Issues?\n\n- [x] Yes, I have checked existing issues and cannot find one related to this.\n\n### Software\n\nDesktop Application\n\n### Operating System / Platform\n\nmacOS Sequoia 15.5\n\n### Your Pieces OS Version\n\n11.4.4\n\n### Early Access Program\n\n- [ ] Yes, this is related to an Early Access Program feature.\n\n### Kindly describe the bug and include as much detail as possible on what you were doing so we can reproduce the bug.\n\n## Bug Report\n\n**Environment:**\n- OS: macOS Sequoia 15.5\n- Pieces OS: 11.4.4 - Running (PID 699, actively collecting data)\n- Pieces App: 4.1.4 - Active with functional LTM workstream\n- MCP Server: Pieces MCP server on localhost:39300\n- Test Client: Warp Terminal Agent Mode, Claude, direct curl testing\n\n## Problem Description\n\nThe `ask_pieces_ltm` MCP tool consistently returns `\"Failed to extract context\"` with `\"isError\": true`, despite:\n\n1. \u2705 **LTM is working correctly** - User confirmed LTM is collecting data and showing results/summaries in the Pieces workstream\n2. \u2705 **MCP server communication works** - Can successfully call `create_pieces_memory` and list tools\n3. \u2705 **Pieces OS is running and active** - Process running with multiple active connections\n4. \u274c **Only `ask_pieces_ltm` fails** - Every call to this specific tool fails\n\n## Steps to Reproduce\n\n### 1. Verify MCP Server is Running\n```bash\nlsof -i :39300\n# Shows Pieces OS listening on port 39300 with multiple established connections\n```\n\n### 2. Confirm Tools are Available\n```bash\ncurl -N http://localhost:39300/model_context_protocol/2024-11-05/sse \\\n  -H 'Accept: text/event-stream' &\ncurl -X POST http://localhost:39300/model_context_protocol/2024-11-05/messages \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\"}'\n```\n\n**Result:** \u2705 Successfully returns tools list with `ask_pieces_ltm` tool schema\n\n### 3. Test create_pieces_memory (Working)\n```bash\ncurl -X POST http://localhost:39300/model_context_protocol/2024-11-05/messages \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"jsonrpc\":\"2.0\",\"id\":2,\"method\":\"tools/call\",\n    \"params\":{\n      \"name\":\"create_pieces_memory\",\n      \"arguments\":{\n        \"summary\":\"Test memory\",\n        \"summary_description\":\"Testing connection\"\n      }\n    }\n  }'\n```\n\n**Result:** \u2705 `\"Long term memory successfully created\"`\n\n### 4. Test ask_pieces_ltm (Failing)\n```bash\ncurl -X POST http://localhost:39300/model_context_protocol/2024-11-05/messages \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"jsonrpc\":\"2.0\",\"id\":3,\"method\":\"tools/call\",\n    \"params\":{\n      \"name\":\"ask_pieces_ltm\",\n      \"arguments\":{\n        \"question\":\"What did I work on today?\",\n        \"chat_llm\":\"claude-3-5-sonnet-20241022\"\n      }\n    }\n  }'\n```\n\n**Result:** \u274c `{\"content\":[{\"type\":\"text\",\"text\":\"Failed to extract context\"}],\"isError\":true}`\n\n## Attempted Variations (All Failed)\n\n### Minimal Parameters\n```json\n{\n  \"question\": \"hello\",\n  \"chat_llm\": \"claude-3-5-sonnet-20241022\"\n}\n```\n\n### With Application Sources\n```json\n{\n  \"question\": \"What terminal commands have I run recently?\",\n  \"chat_llm\": \"claude-3-5-sonnet-20241022\",\n  \"application_sources\": [\"Warp\"],\n  \"connected_client\": \"Warp\"\n}\n```\n\n### Comprehensive Parameters\n```json\n{\n  \"question\": \"What did I work on today?\",\n  \"chat_llm\": \"claude-3-5-sonnet-20241022\",\n  \"connected_client\": \"Warp\",\n  \"application_sources\": [\"Warp\", \"Google Chrome\"],\n  \"topics\": [\"terminal\", \"commands\", \"recent\"],\n  \"related_questions\": [\"What was I working on?\", \"What debugging was I doing?\"]\n}\n```\n\n### Different Application Sources Tested\n- `[\"Warp\"]`\n- `[\"Google Chrome\", \"Safari\", \"Obsidian\"]`\n- `[\"Claude\"]`\n- Multiple combinations from the schema list\n\n**All variations return the same error.**\n\n## Troubleshooting Attempted\n\n1. \u2705 **Restarted Pieces MCP server** - Issue persists\n2. \u2705 **Verified Pieces OS permissions** - Has necessary macOS permissions\n3. \u2705 **Confirmed LTM data collection** - User sees active workstream data\n4. \u2705 **Tested different MCP clients** - Same error in Warp Agent Mode, Claude, and direct curl\n5. \u2705 **Used proper SSE endpoint** - `/sse` for responses, `/messages` for requests\n6. \u2705 **Verified JSON-RPC format** - Matches working `create_pieces_memory` calls\n\n## Expected Behavior\n\nThe `ask_pieces_ltm` tool should return contextual information from the user's LTM data, similar to how the main Pieces application shows workstream summaries and context.\n\n## Actual Behavior\n\nEvery call to `ask_pieces_ltm` returns:\n```json\n{\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": \"Failed to extract context\"\n    }\n  ],\n  \"isError\": true\n}\n```\n\n## Analysis\n\nThis appears to be an **MCP server implementation issue** where:\n\n1. The `ask_pieces_ltm` tool is properly registered and callable\n2. The MCP communication protocol works correctly\n3. The underlying LTM system has data and functions properly\n4. There's a disconnect between the MCP tool implementation and the LTM data access layer\n\n## Potential Root Causes\n\n1. **Authentication/Session Issue**: MCP server process may lack proper authentication to access LTM data\n2. **Data Access Layer Bug**: `ask_pieces_ltm` implementation may be using incorrect API calls to access LTM\n3. **Permissions Issue**: MCP server may not have the same data access permissions as the main Pieces application\n4. **Initialization Problem**: LTM access for MCP tools may require additional setup or initialization\n\n## Request\n\nPlease investigate the `ask_pieces_ltm` tool implementation in the Pieces MCP server to identify why it cannot access the same LTM data that is clearly available to the main Pieces application.\n\n## Additional Context\n\n- Issue occurs consistently across different MCP clients (Warp, Claude)\n- `create_pieces_memory` works perfectly, confirming MCP communication\n- LTM is actively collecting and displaying data in the main Pieces app\n- No relevant error logs found in system logs or Pieces application logs\n- Multiple parameter variations attempted with identical results\n\n\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 4.57
        },
        {
          "id": 755,
          "title": "Pieces has become increasingly slow and is now unresponsive",
          "text": "Pieces has become increasingly slow and is now unresponsive\n### Checked for Existing Issues?\n\n- [x] Yes, I have checked existing issues and cannot find one related to this.\n\n### Software\n\nDesktop Application\n\n### Operating System / Platform\n\nmacOS\n\n### Your Pieces OS Version\n\nVersion 4.2.0 (4.2.0)\n\n### Early Access Program\n\n- [ ] Yes, this is related to an Early Access Program feature.\n\n### Kindly describe the bug and include as much detail as possible on what you were doing so we can reproduce the bug.\n\nI have been using Pieces for many months and it has been an absolute timesaver. \n\nOver the last few weeks, 'New chats' have become increasingly slow, often taking many minutes to get the first response.  This week, it is not responding at all, and failing with the error message: \n\"I'm sorry. Something went wrong with processing. Please wait a few seconds and try again, or contact support@pieces.app\"\n\nI have attempted this with and without LTM enabled and have tried different LLM models - Claude 3.7 Sonnet, Clause 3.5 Sonnect, GPT-4o.    This has not resolved things.\n\nI have independently run the same request with GPT-4o in the browser and the request response is very rapid, so the issue appears to be with the Pieces App, rather than with the LLM\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 5.6
        },
        {
          "id": 754,
          "title": "LTM-2.5 causes Chrome to freeze on large dynamic pages",
          "text": "LTM-2.5 causes Chrome to freeze on large dynamic pages\n### Checked for Existing Issues?\n\n- [x] Yes, I have checked existing issues and cannot find one related to this.\n\n### Software\n\nDesktop Application, Pieces OS\n\n### Operating System / Platform\n\nWindows\n\n### Your Pieces OS Version\n\n12.0.0\n\n### Early Access Program\n\n- [ ] Yes, this is related to an Early Access Program feature.\n\n### Kindly describe the bug and include as much detail as possible on what you were doing so we can reproduce the bug.\n\nWhen browsing webpages with large amounts of content and dynamic elements, Chrome freezes when Pieces OS with LTM 2.5 is active. \n\n[Culprit webpage (Clarity CRM API Docs)](https://claritymobileapi.claritycrm.com/Help/Document) is ~500 KB raw HTML, ~700 KB total page size. Dynamic element(s) are a scroll linked table of contents.\n\n**What happens:**\n\n* Chrome CPU usage spikes (~50% CPU) during scrolling.\n* Memory usage stays stable.\n* Chrome freezes for 10-15 seconds, unfreezes, and freezes again when scrolling resumes.\n* Disabling LTM 2.5 resolves the freeze (Pieces OS still running).\n\n**Expected:**\nPieces should handle large pages without freezing or jumping while scrolling.\n\n---\n\n### **Steps to Reproduce**\n\n1. Enable LTM 2.5 in Pieces OS \n2. Load a large page (https://claritymobileapi.claritycrm.com/Help/Document).\n3. Scroll through the page.\n4. Observe Chrome freeze / become unresponsive as Pieces tries to capture context.\n---\n\n### **Environment**\n\n* OS: Windows 11 Pro\n* Chrome: 137.0.7151.104\n* Pieces OS: 12.0.0\n* LTM Version: 2.5\n* Pieces Chrome Extension: Tested with and without--same result. \n\n---\n\n### **Additional Notes**\n\nI observed high-frequency DOM mutations via MutationObserver, but unsure if root cause (found 80-150 DOM mutations per scroll event)\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 8.83
        }
      ]
    },
    {
      "title": "LTM Activation and Workstream Summary Generation Failures",
      "description": "Users are experiencing issues with LTM-2.5 activation during onboarding, encountering TimeoutExceptions. Additionally, generating workstream summaries is failing with API errors (400, 404). Issues appear across Windows and macOS platforms.  Further investigation into PiecesOS version 12.0.0 and its interaction with LTM and summary generation services is required. Check server logs and connectivity.",
      "frequency": 3,
      "related_issues": [
        {
          "id": 758,
          "title": "Error Activating LTM-2.5 During Onboarding",
          "text": "Error Activating LTM-2.5 During Onboarding\nError: TimeoutException after 0:00:10.000000: Future not completed\n\n**PiecesOS Information**\nCurrent Version: 12.0.0\nosId: a7bab8f7-2ae6-4866-ab26-f14c63dcb535\nuserId: d4f9ba26-4787-4919-b9bb-bf416f7f1937\n\n**Application Information**\nName: PIECES_FOR_DEVELOPERS\nCurrent Version: 4.2.1\n\n**Device Information**\nPlatform: windows\n\nRAM: {memory: 6291456000, speed: -1, type: UNKNOWN}CPUs: ({name: AMD A10-9620P RADEON R5, 10 COMPUTE CORES 4C+6G, l1_cache: -1, l2_cache: 2048, l3_cache: 0, cores: 4, clock_cycle_speed: -1})GPUs: ({name: AMD Radeon R5 Graphics, memory: 1055420416}, {name: Microsoft Basic Render Driver, memory: 0})\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 4.42
        },
        {
          "id": 751,
          "title": "Unable to generate Workstream Summary",
          "text": "Unable to generate Workstream Summary\nError: ApiException 400: HTTP connection failed: POST /workstream_summaries/create/summary (Inner exception: ClientException: Connection closed before full header was received, uri=http://127.0.0.1:39300/workstream_summaries/create/summary)\n\n*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\npid: 360, tid: 6111358976, name io.flutter.ui\nos: macos arch: arm64 comp: no sim: no\nbuild_id: '07f8dd5e45c034b482654a241a0e541e'\nisolate_dso_base: 112b9c000, vm_dso_base: 112b9c000\nisolate_instructions: 112ba9300, vm_instructions: 112b9ea40\n    #00 abs 00000001136eecdb _kDartIsolateSnapshotInstructions+0xb459db\n<asynchronous suspension>\n    #01 abs 0000000113607bef _kDartIsolateSnapshotInstructions+0xa5e8ef\n<asynchronous suspension>\n    #02 abs 000000011364bf87 _kDartIsolateSnapshotInstructions+0xaa2c87\n<asynchronous suspension>\n    #03 abs 000000011364bc0b _kDartIsolateSnapshotInstructions+0xaa290b\n<asynchronous suspension>\n\n\n**Installation Details**\n\nSucceeded: true\nPath: /Applications/Pieces OS.app/Contents/MacOS/Pieces OS\n\n**PiecesOS Information**\n\nID: AA6F5C12-2751-486A-B846-7C6091C6C59D\nUser: 03415321-da89-4fb5-a694-576033517aa5\nCurrent Version: 12.0.0\nMin Version Supported: 12.0.0\nMax Version Supported: 13.0.0\nLocal Port: 39300\n\n**Device Information**\n\nOperating System: MacOS\nCurrent Version: Version 15.2 (Build 24C101)\nMin Version Supported: 12.0.0 Monterey\nAdditional Device Information: {cpu_list: [{\"architecture\":\"arm64\",\"cores\":4,\"logicalProcessors\":4,\"l1Cache\":{\"value\":131072,\"units\":\"Bytes\"},\"l2Cache\":{\"value\":16777216,\"units\":\"Bytes\"},\"description\":\"Apple M4\"}], gpu_list: [], memory_info: {\"totalRAM\":{\"value\":8589934592,\"units\":\"Bytes\"}}, display_list: [{\"nativeHeight\":3086,\"nativeWidth\":5984,\"scaledHeight\":1543,\"scaledWidth\":2992,\"primary\":true}]}\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 6.24
        },
        {
          "id": 459,
          "title": "Bug: unable to cancel the download of an LLLM",
          "text": "Bug: unable to cancel the download of an LLLM\n### Software\n\nDesktop Application\n\n### Operating System / Platform\n\nWindows\n\n### Your Pieces OS Version\n\nlatest\n\n### Early Access Program\n\n- [ ] Yes, this is related to an Early Access Program feature.\n\n### Kindly describe the bug and include as much detail as possible on what you were doing so we can reproduce the bug.\n\n![image](https://github.com/user-attachments/assets/6e730898-a168-4571-ab0d-6331c4d389a4)\r\n\r\ni want stop but its not working \r\n\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 2.65
        }
      ]
    },
    {
      "title": "Workstream activities tab sync issues and download cancellation problems",
      "description": "Users are experiencing problems with the Workstream activities tab not syncing correctly after updates, showing outdated information. Additionally, there are reports of being unable to cancel LLLM downloads, with the cancel button not functioning as expected.  Further investigation is needed to determine the root cause and potential solutions for both issues.",
      "frequency": 3,
      "related_issues": [
        {
          "id": 753,
          "title": "Workstream activities tab is not working",
          "text": "Workstream activities tab is not working\n### Checked for Existing Issues?\n\n- [x] Yes, I have checked existing issues and cannot find one related to this.\n\n### Software\n\nDesktop Application\n\n### Operating System / Platform\n\nmacOS\n\n### Your Pieces OS Version\n\n12.0.0\n\n### Early Access Program\n\n- [ ] Yes, this is related to an Early Access Program feature.\n\n### Kindly describe the bug and include as much detail as possible on what you were doing so we can reproduce the bug.\n\nI faced a sync problem, Can you check it please?\n\nAfter the update, My activities wasn't updated.\nIt's 11pm but activities updated until 5am.\nI used my computer for 0~5am and 7~11pm\n\n![Image](https://github.com/user-attachments/assets/a22b6811-2841-4eb7-b214-36bf4528b702)\n\nI think it can be same with #751 \nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 3.01
        },
        {
          "id": 751,
          "title": "Unable to generate Workstream Summary",
          "text": "Unable to generate Workstream Summary\nError: ApiException 400: HTTP connection failed: POST /workstream_summaries/create/summary (Inner exception: ClientException: Connection closed before full header was received, uri=http://127.0.0.1:39300/workstream_summaries/create/summary)\n\n*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\npid: 360, tid: 6111358976, name io.flutter.ui\nos: macos arch: arm64 comp: no sim: no\nbuild_id: '07f8dd5e45c034b482654a241a0e541e'\nisolate_dso_base: 112b9c000, vm_dso_base: 112b9c000\nisolate_instructions: 112ba9300, vm_instructions: 112b9ea40\n    #00 abs 00000001136eecdb _kDartIsolateSnapshotInstructions+0xb459db\n<asynchronous suspension>\n    #01 abs 0000000113607bef _kDartIsolateSnapshotInstructions+0xa5e8ef\n<asynchronous suspension>\n    #02 abs 000000011364bf87 _kDartIsolateSnapshotInstructions+0xaa2c87\n<asynchronous suspension>\n    #03 abs 000000011364bc0b _kDartIsolateSnapshotInstructions+0xaa290b\n<asynchronous suspension>\n\n\n**Installation Details**\n\nSucceeded: true\nPath: /Applications/Pieces OS.app/Contents/MacOS/Pieces OS\n\n**PiecesOS Information**\n\nID: AA6F5C12-2751-486A-B846-7C6091C6C59D\nUser: 03415321-da89-4fb5-a694-576033517aa5\nCurrent Version: 12.0.0\nMin Version Supported: 12.0.0\nMax Version Supported: 13.0.0\nLocal Port: 39300\n\n**Device Information**\n\nOperating System: MacOS\nCurrent Version: Version 15.2 (Build 24C101)\nMin Version Supported: 12.0.0 Monterey\nAdditional Device Information: {cpu_list: [{\"architecture\":\"arm64\",\"cores\":4,\"logicalProcessors\":4,\"l1Cache\":{\"value\":131072,\"units\":\"Bytes\"},\"l2Cache\":{\"value\":16777216,\"units\":\"Bytes\"},\"description\":\"Apple M4\"}], gpu_list: [], memory_info: {\"totalRAM\":{\"value\":8589934592,\"units\":\"Bytes\"}}, display_list: [{\"nativeHeight\":3086,\"nativeWidth\":5984,\"scaledHeight\":1543,\"scaledWidth\":2992,\"primary\":true}]}\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 6.24
        },
        {
          "id": 459,
          "title": "Bug: unable to cancel the download of an LLLM",
          "text": "Bug: unable to cancel the download of an LLLM\n### Software\n\nDesktop Application\n\n### Operating System / Platform\n\nWindows\n\n### Your Pieces OS Version\n\nlatest\n\n### Early Access Program\n\n- [ ] Yes, this is related to an Early Access Program feature.\n\n### Kindly describe the bug and include as much detail as possible on what you were doing so we can reproduce the bug.\n\n![image](https://github.com/user-attachments/assets/6e730898-a168-4571-ab0d-6331c4d389a4)\r\n\r\ni want stop but its not working \r\n\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 2.65
        }
      ]
    },
    {
      "title": "PiecesOS Cloud Service Interruption and Performance Degradation",
      "description": "Users are experiencing slow performance and unresponsiveness in PiecesOS, Desktop App, and plugins, especially with cloud-connected features like Copilot, Workstream summaries, snippet transforms, and snippet discovery.  A service interruption is being investigated, including the possibility of a cyber-related incident.  Data security is not believed to be impacted.  The Pieces team is working to restore full functionality.",
      "frequency": 3,
      "related_issues": [
        {
          "id": 756,
          "title": "\ud83d\udea8 Ongoing Service Interruption Impacting Pieces Products and Cloud-Connected Features",
          "text": "\ud83d\udea8 Ongoing Service Interruption Impacting Pieces Products and Cloud-Connected Features\nWe are currently experiencing a service interruption affecting several cloud-connected features across PiecesOS, the Desktop App, and Pieces Plugins. Specifically, users may notice degraded performance or unresponsiveness in the following areas:\n\n- Copilot responses\n- Workstream summaries\n- Other cloud-assisted functionalities, such as snippet transforms and snippet discovery\n\nThe interruption is tied to unexpected issues with specific cloud services, and we are also actively investigating the possibility of a cyber-related incident as part of our root cause analysis.\n\nWe want to reassure all users that your data security and privacy are not impacted. As a precaution, our security and infrastructure teams are treating this with the highest level of urgency and diligence. We are taking all necessary steps to investigate and remediate the issue.\n\nOur engineering and security teams are working around the clock to restore full functionality. We\u2019ll continue to provide updates in this thread as we learn more and make progress.\n\nYou can track the status of this interruption here and we\u2019ll notify you once normal service has resumed.\n\nWe deeply appreciate your patience and understanding during this time. If you have urgent concerns or need support, please reach out via our usual support channels.\n\nThe Pieces Team\nNo comments found on this issue.",
          "activity_level": 2.15
        },
        {
          "id": 755,
          "title": "Pieces has become increasingly slow and is now unresponsive",
          "text": "Pieces has become increasingly slow and is now unresponsive\n### Checked for Existing Issues?\n\n- [x] Yes, I have checked existing issues and cannot find one related to this.\n\n### Software\n\nDesktop Application\n\n### Operating System / Platform\n\nmacOS\n\n### Your Pieces OS Version\n\nVersion 4.2.0 (4.2.0)\n\n### Early Access Program\n\n- [ ] Yes, this is related to an Early Access Program feature.\n\n### Kindly describe the bug and include as much detail as possible on what you were doing so we can reproduce the bug.\n\nI have been using Pieces for many months and it has been an absolute timesaver. \n\nOver the last few weeks, 'New chats' have become increasingly slow, often taking many minutes to get the first response.  This week, it is not responding at all, and failing with the error message: \n\"I'm sorry. Something went wrong with processing. Please wait a few seconds and try again, or contact support@pieces.app\"\n\nI have attempted this with and without LTM enabled and have tried different LLM models - Claude 3.7 Sonnet, Clause 3.5 Sonnect, GPT-4o.    This has not resolved things.\n\nI have independently run the same request with GPT-4o in the browser and the request response is very rapid, so the issue appears to be with the Pieces App, rather than with the LLM\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 5.6
        },
        {
          "id": 752,
          "title": "Doesn't move past Initialising Desktop screen",
          "text": "Doesn't move past Initialising Desktop screen\n### Checked for Existing Issues?\n\n- [x] Yes, I have checked existing issues and cannot find one related to this.\n\n### Software\n\nDesktop Application\n\n### Operating System / Platform\n\nLinux\n\n### Your Pieces OS Version\n\n12.0.0\n\n### Early Access Program\n\n- [ ] Yes, this is related to an Early Access Program feature.\n\n### Kindly describe the bug and include as much detail as possible on what you were doing so we can reproduce the bug.\n\nHi team,\n\nYesterday (15th June 2025), a new pieces version got released on snap. The new version broke the installation completely and the Desktop application doesn't move past the first step of initialization itself. I thought it was a problem with my system, but I tried a fresh install on a completely different device and same behaviour was observed. Please let me know if there is a way to revert back to the older version till the time this issue gets resolved. Also, please let me know if any further details are required to assist you with the resolution.\n\nDistro: Ubuntu 24.04\nArch: x86_64\n\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 3.01
        }
      ]
    }
  ],
  "recommendations": [
    "Prioritize resolving the MCP `ask_pieces_ltm` tool issue, as it impacts core functionality and has a high frequency.",
    "Investigate and address the LTM-2.5 activation and workstream summary generation failures, especially focusing on PiecesOS 12.0.0 compatibility.",
    "Address the performance issues and unresponsiveness related to the ongoing service interruption, prioritizing cloud-connected features.",
    "Improve communication with users regarding the service interruption and provide regular updates on the resolution progress.",
    "Investigate the reports of Chrome freezing on large dynamic pages when LTM-2.5 is active, optimizing LTM resource usage.",
    "Ensure the LLLM download cancellation functionality is working as expected across all platforms.",
    "Investigate and fix the Workstream activities tab sync issues to ensure users have accurate information.",
    "Review and update onboarding documentation and processes related to LTM-2.5 activation to minimize user errors.",
    "Monitor server logs and performance metrics to proactively identify and address potential issues.",
    "Gather more user feedback on specific issues to better understand the impact and prioritize fixes accordingly.",
    "Consider implementing automated tests for critical features like LTM activation, workstream summary generation, and LLLM download cancellation to prevent regressions.",
    "Allocate resources to address the most active tickets based on activity level and user impact.",
    "Improve error handling and messaging within the Pieces app to provide more informative and actionable error messages to users.",
    "Develop a more robust incident management process to handle service interruptions and other critical issues more effectively.",
    "Proactively monitor system performance and stability to identify and address potential issues before they impact users.",
    "Enhance internal communication and collaboration between support, engineering, and product teams to facilitate faster issue resolution.",
    "Invest in tools and resources to improve support efficiency and response times.",
    "Develop a knowledge base or FAQ section to address common user questions and issues.",
    "Provide training to support staff on new features and troubleshooting techniques.",
    "Regularly analyze support data to identify trends, common issues, and areas for improvement in the product and support processes.",
    "Implement a system for tracking and prioritizing bug fixes and feature requests based on user feedback and support data.",
    "Encourage users to report issues through the appropriate channels and provide clear instructions on how to do so.",
    "Consider implementing a user forum or community platform to facilitate peer-to-peer support and knowledge sharing.",
    "Regularly review and update support documentation and resources to ensure they are accurate and up-to-date.",
    "Conduct user surveys and feedback sessions to gather insights on user satisfaction with the product and support services.",
    "Analyze user behavior and usage patterns to identify potential areas for improvement in the product and support processes.",
    "Implement a system for measuring and tracking key support metrics such as resolution time, customer satisfaction, and ticket volume.",
    "Use data-driven insights to continuously improve support operations and enhance the user experience.",
    "Establish clear service level agreements (SLAs) for support response times and resolution times.",
    "Communicate SLAs to users so they have clear expectations for support service delivery.",
    "Regularly review and update SLAs based on performance data and user feedback.",
    "Provide support staff with the necessary tools and resources to meet SLAs and deliver high-quality support.",
    "Empower support staff to resolve issues efficiently and effectively by providing them with the necessary authority and autonomy.",
    "Foster a positive and supportive work environment for support staff to promote job satisfaction and reduce turnover.",
    "Recognize and reward support staff for their contributions to improving the user experience.",
    "Invest in ongoing training and development for support staff to enhance their skills and knowledge.",
    "Promote a culture of continuous improvement within the support team by encouraging feedback and innovation.",
    "Regularly review and update support processes and procedures to optimize efficiency and effectiveness.",
    "Implement a system for tracking and managing support requests across multiple channels such as email, chat, and phone.",
    "Integrate support tools with other systems such as CRM and ticketing systems to streamline workflows and improve data management.",
    "Automate routine support tasks such as ticket routing and notification to free up support staff to focus on more complex issues.",
    "Use artificial intelligence and machine learning to automate support tasks such as answering common questions and triaging tickets.",
    "Personalize support interactions by using user data and context to provide tailored solutions and recommendations.",
    "Proactively reach out to users who are experiencing issues or who may benefit from additional support.",
    "Provide self-service support options such as knowledge bases, FAQs, and tutorials to empower users to resolve issues on their own.",
    "Offer multilingual support to cater to a diverse user base.",
    "Provide support across multiple time zones to ensure users can access support when they need it.",
    "Monitor social media and online forums for user feedback and issues.",
    "Respond to user feedback and issues in a timely and professional manner.",
    "Use social media and online forums to engage with users and build community.",
    "Proactively share helpful tips and resources with users through social media and online forums.",
    "Use social media and online forums to gather user feedback and insights on product development and support services.",
    "Analyze social media and online forum data to identify trends and emerging issues.",
    "Use social media and online forum data to inform product development and support strategies.",
    "Collaborate with other teams such as marketing and product management to align support efforts with overall business goals.",
    "Communicate regularly with other teams to share insights and best practices.",
    "Participate in cross-functional initiatives to improve the user experience across all touchpoints.",
    "Continuously evaluate and improve support operations to ensure they are meeting the needs of users and the business.",
    "Stay up-to-date on industry best practices and emerging trends in customer support.",
    "Adapt support strategies and processes to meet the evolving needs of users and the business.",
    "Be proactive in identifying and addressing potential challenges and opportunities in the support landscape.",
    "Strive to deliver exceptional customer support that exceeds user expectations and builds loyalty.",
    "View customer support as a strategic investment that contributes to the overall success of the business.",
    "Empower support staff to act as brand ambassadors and advocates for users.",
    "Build a strong relationship between the support team and the user community.",
    "Foster a culture of customer-centricity within the support team and across the organization.",
    "Measure and track the impact of support operations on key business metrics such as customer retention and lifetime value.",
    "Use data to demonstrate the value of customer support to the business.",
    "Advocate for resources and investment in customer support to ensure its continued success.",
    "Continuously innovate and experiment with new approaches to customer support to improve efficiency and effectiveness.",
    "Embrace new technologies and tools to enhance support operations and deliver a better user experience.",
    "Share best practices and lessons learned with other teams and organizations to contribute to the advancement of the customer support field.",
    "Be a leader in customer support by setting high standards and driving innovation.",
    "Inspire and motivate support staff to deliver exceptional service and make a positive impact on users' lives.",
    "Create a support organization that is recognized for its excellence and its contribution to the success of the business.",
    "Build a world-class customer support operation that sets the standard for others to follow.",
    "Transform customer support from a cost center to a value driver for the business.",
    "Make customer support a key differentiator for the business and a source of competitive advantage.",
    "Create a customer-centric culture that permeates the entire organization and drives sustainable growth.",
    "Empower users to achieve their goals and succeed by providing them with exceptional support and resources.",
    "Build a loyal user base that advocates for the business and contributes to its long-term success.",
    "Make a positive impact on the world by providing outstanding customer support and empowering users to thrive."
  ],
  "message": "Daily support report generated successfully."
}