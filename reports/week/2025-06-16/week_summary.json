{
  "success": true,
  "date_range": {
    "start": "2025-06-16T00:00:00+00:00",
    "end": "2025-06-19T13:16:39.454364+00:00"
  },
  "summary": {
    "total_tickets": 10,
    "resolved_tickets": 0,
    "open_tickets": 10
  },
  "ticket_breakdown": [
    {
      "category": "bug",
      "received": 10,
      "resolved": 0,
      "pending": 10
    },
    {
      "category": "status:new",
      "received": 2,
      "resolved": 0,
      "pending": 2
    },
    {
      "category": "app:desktop application",
      "received": 8,
      "resolved": 0,
      "pending": 8
    },
    {
      "category": "os:macos",
      "received": 5,
      "resolved": 0,
      "pending": 5
    },
    {
      "category": "os:linux",
      "received": 2,
      "resolved": 0,
      "pending": 2
    },
    {
      "category": "status:triaged",
      "received": 8,
      "resolved": 0,
      "pending": 8
    },
    {
      "category": "app:pieces cli",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "os:windows",
      "received": 2,
      "resolved": 0,
      "pending": 2
    },
    {
      "category": "app:pieces os",
      "received": 4,
      "resolved": 0,
      "pending": 4
    },
    {
      "category": "app:jetbrains",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "app:vs code",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "app:jupyterlab",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "app:web extension",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "app:obsidian",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "app:visual studio",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "app:cli",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "app:neovim",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "app:sublime plugin",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "app:raycast plugin",
      "received": 1,
      "resolved": 0,
      "pending": 1
    },
    {
      "category": "maintenance_ongoing",
      "received": 4,
      "resolved": 0,
      "pending": 4
    },
    {
      "category": "provide_status_update_on_resolution",
      "received": 4,
      "resolved": 0,
      "pending": 4
    }
  ],
  "most_active_tickets": [
    {
      "number": 754,
      "title": "LTM-2.5 causes Chrome to freeze on large dynamic pages",
      "activity_level": 7.93
    },
    {
      "number": 751,
      "title": "Unable to generate Workstream Summary",
      "activity_level": 5.61
    },
    {
      "number": 755,
      "title": "Pieces has become increasingly slow and is now unresponsive",
      "activity_level": 5.03
    },
    {
      "number": 759,
      "title": "Can't login/authentication message won't arrive",
      "activity_level": 4.42
    },
    {
      "number": 758,
      "title": "Error Activating LTM-2.5 During Onboarding",
      "activity_level": 4.42
    },
    {
      "number": 747,
      "title": "MCP `ask_pieces_ltm` tool consistently returns \"Failed to extract context\" despite functional LTM",
      "activity_level": 4.36
    },
    {
      "number": 752,
      "title": "Doesn't move past Initialising Desktop screen",
      "activity_level": 4.26
    },
    {
      "number": 753,
      "title": "Workstream activities tab is not working",
      "activity_level": 2.71
    },
    {
      "number": 459,
      "title": "Bug: unable to cancel the download of an LLLM",
      "activity_level": 2.64
    },
    {
      "number": 756,
      "title": "\ud83d\udea8 Ongoing Service Interruption Impacting Pieces Products and Cloud-Connected Features",
      "activity_level": 2.15
    }
  ],
  "common_issues": [
    {
      "title": "Pieces Fails to Access LTM Data via MCP",
      "description": "The `ask_pieces_ltm` MCP tool consistently returns \"Failed to extract context\" error, despite functional LTM within the Pieces application.  This affects various clients (Warp, Claude, curl) and persists across restarts and parameter variations.  Other MCP tools like `create_pieces_memory` work correctly. The issue likely lies in the MCP server's interaction with the LTM data access layer, possibly due to authentication, permissions, or initialization problems. ",
      "frequency": 3,
      "related_issues": [
        {
          "id": 747,
          "title": "MCP `ask_pieces_ltm` tool consistently returns \"Failed to extract context\" despite functional LTM",
          "text": "MCP `ask_pieces_ltm` tool consistently returns \"Failed to extract context\" despite functional LTM\n### Checked for Existing Issues?\n\n- [x] Yes, I have checked existing issues and cannot find one related to this.\n\n### Software\n\nDesktop Application\n\n### Operating System / Platform\n\nmacOS Sequoia 15.5\n\n### Your Pieces OS Version\n\n11.4.4\n\n### Early Access Program\n\n- [ ] Yes, this is related to an Early Access Program feature.\n\n### Kindly describe the bug and include as much detail as possible on what you were doing so we can reproduce the bug.\n\n## Bug Report\n\n**Environment:**\n- OS: macOS Sequoia 15.5\n- Pieces OS: 11.4.4 - Running (PID 699, actively collecting data)\n- Pieces App: 4.1.4 - Active with functional LTM workstream\n- MCP Server: Pieces MCP server on localhost:39300\n- Test Client: Warp Terminal Agent Mode, Claude, direct curl testing\n\n## Problem Description\n\nThe `ask_pieces_ltm` MCP tool consistently returns `\"Failed to extract context\"` with `\"isError\": true`, despite:\n\n1. \u2705 **LTM is working correctly** - User confirmed LTM is collecting data and showing results/summaries in the Pieces workstream\n2. \u2705 **MCP server communication works** - Can successfully call `create_pieces_memory` and list tools\n3. \u2705 **Pieces OS is running and active** - Process running with multiple active connections\n4. \u274c **Only `ask_pieces_ltm` fails** - Every call to this specific tool fails\n\n## Steps to Reproduce\n\n### 1. Verify MCP Server is Running\n```bash\nlsof -i :39300\n# Shows Pieces OS listening on port 39300 with multiple established connections\n```\n\n### 2. Confirm Tools are Available\n```bash\ncurl -N http://localhost:39300/model_context_protocol/2024-11-05/sse \\\n  -H 'Accept: text/event-stream' &\ncurl -X POST http://localhost:39300/model_context_protocol/2024-11-05/messages \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\"}'\n```\n\n**Result:** \u2705 Successfully returns tools list with `ask_pieces_ltm` tool schema\n\n### 3. Test create_pieces_memory (Working)\n```bash\ncurl -X POST http://localhost:39300/model_context_protocol/2024-11-05/messages \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"jsonrpc\":\"2.0\",\"id\":2,\"method\":\"tools/call\",\n    \"params\":{\n      \"name\":\"create_pieces_memory\",\n      \"arguments\":{\n        \"summary\":\"Test memory\",\n        \"summary_description\":\"Testing connection\"\n      }\n    }\n  }'\n```\n\n**Result:** \u2705 `\"Long term memory successfully created\"`\n\n### 4. Test ask_pieces_ltm (Failing)\n```bash\ncurl -X POST http://localhost:39300/model_context_protocol/2024-11-05/messages \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"jsonrpc\":\"2.0\",\"id\":3,\"method\":\"tools/call\",\n    \"params\":{\n      \"name\":\"ask_pieces_ltm\",\n      \"arguments\":{\n        \"question\":\"What did I work on today?\",\n        \"chat_llm\":\"claude-3-5-sonnet-20241022\"\n      }\n    }\n  }'\n```\n\n**Result:** \u274c `{\"content\":[{\"type\":\"text\",\"text\":\"Failed to extract context\"}],\"isError\":true}`\n\n## Attempted Variations (All Failed)\n\n### Minimal Parameters\n```json\n{\n  \"question\": \"hello\",\n  \"chat_llm\": \"claude-3-5-sonnet-20241022\"\n}\n```\n\n### With Application Sources\n```json\n{\n  \"question\": \"What terminal commands have I run recently?\",\n  \"chat_llm\": \"claude-3-5-sonnet-20241022\",\n  \"application_sources\": [\"Warp\"],\n  \"connected_client\": \"Warp\"\n}\n```\n\n### Comprehensive Parameters\n```json\n{\n  \"question\": \"What did I work on today?\",\n  \"chat_llm\": \"claude-3-5-sonnet-20241022\",\n  \"connected_client\": \"Warp\",\n  \"application_sources\": [\"Warp\", \"Google Chrome\"],\n  \"topics\": [\"terminal\", \"commands\", \"recent\"],\n  \"related_questions\": [\"What was I working on?\", \"What debugging was I doing?\"]\n}\n```\n\n### Different Application Sources Tested\n- `[\"Warp\"]`\n- `[\"Google Chrome\", \"Safari\", \"Obsidian\"]`\n- `[\"Claude\"]`\n- Multiple combinations from the schema list\n\n**All variations return the same error.**\n\n## Troubleshooting Attempted\n\n1. \u2705 **Restarted Pieces MCP server** - Issue persists\n2. \u2705 **Verified Pieces OS permissions** - Has necessary macOS permissions\n3. \u2705 **Confirmed LTM data collection** - User sees active workstream data\n4. \u2705 **Tested different MCP clients** - Same error in Warp Agent Mode, Claude, and direct curl\n5. \u2705 **Used proper SSE endpoint** - `/sse` for responses, `/messages` for requests\n6. \u2705 **Verified JSON-RPC format** - Matches working `create_pieces_memory` calls\n\n## Expected Behavior\n\nThe `ask_pieces_ltm` tool should return contextual information from the user's LTM data, similar to how the main Pieces application shows workstream summaries and context.\n\n## Actual Behavior\n\nEvery call to `ask_pieces_ltm` returns:\n```json\n{\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": \"Failed to extract context\"\n    }\n  ],\n  \"isError\": true\n}\n```\n\n## Analysis\n\nThis appears to be an **MCP server implementation issue** where:\n\n1. The `ask_pieces_ltm` tool is properly registered and callable\n2. The MCP communication protocol works correctly\n3. The underlying LTM system has data and functions properly\n4. There's a disconnect between the MCP tool implementation and the LTM data access layer\n\n## Potential Root Causes\n\n1. **Authentication/Session Issue**: MCP server process may lack proper authentication to access LTM data\n2. **Data Access Layer Bug**: `ask_pieces_ltm` implementation may be using incorrect API calls to access LTM\n3. **Permissions Issue**: MCP server may not have the same data access permissions as the main Pieces application\n4. **Initialization Problem**: LTM access for MCP tools may require additional setup or initialization\n\n## Request\n\nPlease investigate the `ask_pieces_ltm` tool implementation in the Pieces MCP server to identify why it cannot access the same LTM data that is clearly available to the main Pieces application.\n\n## Additional Context\n\n- Issue occurs consistently across different MCP clients (Warp, Claude)\n- `create_pieces_memory` works perfectly, confirming MCP communication\n- LTM is actively collecting and displaying data in the main Pieces app\n- No relevant error logs found in system logs or Pieces application logs\n- Multiple parameter variations attempted with identical results\n\n\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 4.36
        },
        {
          "id": 755,
          "title": "Pieces has become increasingly slow and is now unresponsive",
          "text": "Pieces has become increasingly slow and is now unresponsive\n### Checked for Existing Issues?\n\n- [x] Yes, I have checked existing issues and cannot find one related to this.\n\n### Software\n\nDesktop Application\n\n### Operating System / Platform\n\nmacOS\n\n### Your Pieces OS Version\n\nVersion 4.2.0 (4.2.0)\n\n### Early Access Program\n\n- [ ] Yes, this is related to an Early Access Program feature.\n\n### Kindly describe the bug and include as much detail as possible on what you were doing so we can reproduce the bug.\n\nI have been using Pieces for many months and it has been an absolute timesaver. \n\nOver the last few weeks, 'New chats' have become increasingly slow, often taking many minutes to get the first response.  This week, it is not responding at all, and failing with the error message: \n\"I'm sorry. Something went wrong with processing. Please wait a few seconds and try again, or contact support@pieces.app\"\n\nI have attempted this with and without LTM enabled and have tried different LLM models - Claude 3.7 Sonnet, Clause 3.5 Sonnect, GPT-4o.    This has not resolved things.\n\nI have independently run the same request with GPT-4o in the browser and the request response is very rapid, so the issue appears to be with the Pieces App, rather than with the LLM\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 5.03
        },
        {
          "id": 754,
          "title": "LTM-2.5 causes Chrome to freeze on large dynamic pages",
          "text": "LTM-2.5 causes Chrome to freeze on large dynamic pages\n### Checked for Existing Issues?\n\n- [x] Yes, I have checked existing issues and cannot find one related to this.\n\n### Software\n\nDesktop Application, Pieces OS\n\n### Operating System / Platform\n\nWindows\n\n### Your Pieces OS Version\n\n12.0.0\n\n### Early Access Program\n\n- [ ] Yes, this is related to an Early Access Program feature.\n\n### Kindly describe the bug and include as much detail as possible on what you were doing so we can reproduce the bug.\n\nWhen browsing webpages with large amounts of content and dynamic elements, Chrome freezes when Pieces OS with LTM 2.5 is active. \n\n[Culprit webpage (Clarity CRM API Docs)](https://claritymobileapi.claritycrm.com/Help/Document) is ~500 KB raw HTML, ~700 KB total page size. Dynamic element(s) are a scroll linked table of contents.\n\n**What happens:**\n\n* Chrome CPU usage spikes (~50% CPU) during scrolling.\n* Memory usage stays stable.\n* Chrome freezes for 10-15 seconds, unfreezes, and freezes again when scrolling resumes.\n* Disabling LTM 2.5 resolves the freeze (Pieces OS still running).\n\n**Expected:**\nPieces should handle large pages without freezing or jumping while scrolling.\n\n---\n\n### **Steps to Reproduce**\n\n1. Enable LTM 2.5 in Pieces OS \n2. Load a large page (https://claritymobileapi.claritycrm.com/Help/Document).\n3. Scroll through the page.\n4. Observe Chrome freeze / become unresponsive as Pieces tries to capture context.\n---\n\n### **Environment**\n\n* OS: Windows 11 Pro\n* Chrome: 137.0.7151.104\n* Pieces OS: 12.0.0\n* LTM Version: 2.5\n* Pieces Chrome Extension: Tested with and without--same result. \n\n---\n\n### **Additional Notes**\n\nI observed high-frequency DOM mutations via MutationObserver, but unsure if root cause (found 80-150 DOM mutations per scroll event)\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 7.93
        }
      ]
    },
    {
      "title": "Pieces Desktop App Issues on macOS and Linux",
      "description": "Users are experiencing various issues with the Pieces desktop app, including login failures due to missing verification codes on macOS, slow performance and unresponsiveness on macOS, and failure to initialize past the initial screen on Linux after the latest update.  Suggested solutions include checking online authentication services, optimizing app performance, and investigating compatibility issues with the latest update on Linux. Further investigation is needed to pinpoint the root causes and provide specific fixes.",
      "frequency": 3,
      "related_issues": [
        {
          "id": 759,
          "title": "Can't login/authentication message won't arrive",
          "text": "Can't login/authentication message won't arrive\n### Checked for Existing Issues?\n\n- [x] Yes, I have checked existing issues and cannot find one related to this.\n\n### Software\n\nDesktop Application\n\n### Operating System / Platform\n\nmacOS\n\n### Your Pieces OS Version\n\n12.0.0\n\n### Early Access Program\n\n- [ ] Yes, this is related to an Early Access Program feature.\n\n### Kindly describe the bug and include as much detail as possible on what you were doing so we can reproduce the bug.\n\nI haven't been online a lot because of personal issues. Yesterday I restarted pieces for the first time in weeks, and it said I needed to sign in before I can continue.\nFirst the sign in link wouldn't work. Then I noticed there was a Pieces OS update too. After I clicked that update I got back to the same screen and the link would work.\nSo I entered my mail address and it said I should get a verification code, which never arrived. So I tried again later and still nothing happened. I decided to let it rest until today and try it again, but still the same result.\n\nAlso, please allow people to continue offline if you can't get your online authentication to work properly.\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 4.42
        },
        {
          "id": 755,
          "title": "Pieces has become increasingly slow and is now unresponsive",
          "text": "Pieces has become increasingly slow and is now unresponsive\n### Checked for Existing Issues?\n\n- [x] Yes, I have checked existing issues and cannot find one related to this.\n\n### Software\n\nDesktop Application\n\n### Operating System / Platform\n\nmacOS\n\n### Your Pieces OS Version\n\nVersion 4.2.0 (4.2.0)\n\n### Early Access Program\n\n- [ ] Yes, this is related to an Early Access Program feature.\n\n### Kindly describe the bug and include as much detail as possible on what you were doing so we can reproduce the bug.\n\nI have been using Pieces for many months and it has been an absolute timesaver. \n\nOver the last few weeks, 'New chats' have become increasingly slow, often taking many minutes to get the first response.  This week, it is not responding at all, and failing with the error message: \n\"I'm sorry. Something went wrong with processing. Please wait a few seconds and try again, or contact support@pieces.app\"\n\nI have attempted this with and without LTM enabled and have tried different LLM models - Claude 3.7 Sonnet, Clause 3.5 Sonnect, GPT-4o.    This has not resolved things.\n\nI have independently run the same request with GPT-4o in the browser and the request response is very rapid, so the issue appears to be with the Pieces App, rather than with the LLM\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 5.03
        },
        {
          "id": 752,
          "title": "Doesn't move past Initialising Desktop screen",
          "text": "Doesn't move past Initialising Desktop screen\n### Checked for Existing Issues?\n\n- [x] Yes, I have checked existing issues and cannot find one related to this.\n\n### Software\n\nDesktop Application\n\n### Operating System / Platform\n\nLinux\n\n### Your Pieces OS Version\n\n12.0.0\n\n### Early Access Program\n\n- [ ] Yes, this is related to an Early Access Program feature.\n\n### Kindly describe the bug and include as much detail as possible on what you were doing so we can reproduce the bug.\n\nHi team,\n\nYesterday (15th June 2025), a new pieces version got released on snap. The new version broke the installation completely and the Desktop application doesn't move past the first step of initialization itself. I thought it was a problem with my system, but I tried a fresh install on a completely different device and same behaviour was observed. Please let me know if there is a way to revert back to the older version till the time this issue gets resolved. Also, please let me know if any further details are required to assist you with the resolution.\n\nDistro: Ubuntu 24.04\nArch: x86_64\n\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 4.26
        }
      ]
    },
    {
      "title": "LTM Activation and Workstream Summary Generation Errors",
      "description": "Users are experiencing issues with LTM-2.5 activation during onboarding, encountering TimeoutExceptions. Additionally, generating workstream summaries is failing with HTTP connection errors.  The PiecesOS version is 12.0.0. Further investigation into the LTM activation process and API endpoints for workstream summaries is needed. Download cancellation for LLLMs is also reported as non-functional.",
      "frequency": 3,
      "related_issues": [
        {
          "id": 758,
          "title": "Error Activating LTM-2.5 During Onboarding",
          "text": "Error Activating LTM-2.5 During Onboarding\nError: TimeoutException after 0:00:10.000000: Future not completed\n\n**PiecesOS Information**\nCurrent Version: 12.0.0\nosId: a7bab8f7-2ae6-4866-ab26-f14c63dcb535\nuserId: d4f9ba26-4787-4919-b9bb-bf416f7f1937\n\n**Application Information**\nName: PIECES_FOR_DEVELOPERS\nCurrent Version: 4.2.1\n\n**Device Information**\nPlatform: windows\n\nRAM: {memory: 6291456000, speed: -1, type: UNKNOWN}CPUs: ({name: AMD A10-9620P RADEON R5, 10 COMPUTE CORES 4C+6G, l1_cache: -1, l2_cache: 2048, l3_cache: 0, cores: 4, clock_cycle_speed: -1})GPUs: ({name: AMD Radeon R5 Graphics, memory: 1055420416}, {name: Microsoft Basic Render Driver, memory: 0})\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 4.42
        },
        {
          "id": 751,
          "title": "Unable to generate Workstream Summary",
          "text": "Unable to generate Workstream Summary\nError: ApiException 400: HTTP connection failed: POST /workstream_summaries/create/summary (Inner exception: ClientException: Connection closed before full header was received, uri=http://127.0.0.1:39300/workstream_summaries/create/summary)\n\n*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\npid: 360, tid: 6111358976, name io.flutter.ui\nos: macos arch: arm64 comp: no sim: no\nbuild_id: '07f8dd5e45c034b482654a241a0e541e'\nisolate_dso_base: 112b9c000, vm_dso_base: 112b9c000\nisolate_instructions: 112ba9300, vm_instructions: 112b9ea40\n    #00 abs 00000001136eecdb _kDartIsolateSnapshotInstructions+0xb459db\n<asynchronous suspension>\n    #01 abs 0000000113607bef _kDartIsolateSnapshotInstructions+0xa5e8ef\n<asynchronous suspension>\n    #02 abs 000000011364bf87 _kDartIsolateSnapshotInstructions+0xaa2c87\n<asynchronous suspension>\n    #03 abs 000000011364bc0b _kDartIsolateSnapshotInstructions+0xaa290b\n<asynchronous suspension>\n\n\n**Installation Details**\n\nSucceeded: true\nPath: /Applications/Pieces OS.app/Contents/MacOS/Pieces OS\n\n**PiecesOS Information**\n\nID: AA6F5C12-2751-486A-B846-7C6091C6C59D\nUser: 03415321-da89-4fb5-a694-576033517aa5\nCurrent Version: 12.0.0\nMin Version Supported: 12.0.0\nMax Version Supported: 13.0.0\nLocal Port: 39300\n\n**Device Information**\n\nOperating System: MacOS\nCurrent Version: Version 15.2 (Build 24C101)\nMin Version Supported: 12.0.0 Monterey\nAdditional Device Information: {cpu_list: [{\"architecture\":\"arm64\",\"cores\":4,\"logicalProcessors\":4,\"l1Cache\":{\"value\":131072,\"units\":\"Bytes\"},\"l2Cache\":{\"value\":16777216,\"units\":\"Bytes\"},\"description\":\"Apple M4\"}], gpu_list: [], memory_info: {\"totalRAM\":{\"value\":8589934592,\"units\":\"Bytes\"}}, display_list: [{\"nativeHeight\":3086,\"nativeWidth\":5984,\"scaledHeight\":1543,\"scaledWidth\":2992,\"primary\":true}]}\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 5.61
        },
        {
          "id": 459,
          "title": "Bug: unable to cancel the download of an LLLM",
          "text": "Bug: unable to cancel the download of an LLLM\n### Software\n\nDesktop Application\n\n### Operating System / Platform\n\nWindows\n\n### Your Pieces OS Version\n\nlatest\n\n### Early Access Program\n\n- [ ] Yes, this is related to an Early Access Program feature.\n\n### Kindly describe the bug and include as much detail as possible on what you were doing so we can reproduce the bug.\n\n![image](https://github.com/user-attachments/assets/6e730898-a168-4571-ab0d-6331c4d389a4)\r\n\r\ni want stop but its not working \r\n\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 2.64
        }
      ]
    },
    {
      "title": "Pieces Cloud Service Interruption Affecting Multiple Features",
      "description": "Users are experiencing slow performance or unresponsiveness with cloud-connected features like Copilot, Workstream summaries, snippet transforms, and snippet discovery.  Pieces is investigating cloud service issues and a potential cyber-related incident.  Data security is not impacted.  The engineering team is working to restore full functionality.",
      "frequency": 3,
      "related_issues": [
        {
          "id": 756,
          "title": "\ud83d\udea8 Ongoing Service Interruption Impacting Pieces Products and Cloud-Connected Features",
          "text": "\ud83d\udea8 Ongoing Service Interruption Impacting Pieces Products and Cloud-Connected Features\nWe are currently experiencing a service interruption affecting several cloud-connected features across PiecesOS, the Desktop App, and Pieces Plugins. Specifically, users may notice degraded performance or unresponsiveness in the following areas:\n\n- Copilot responses\n- Workstream summaries\n- Other cloud-assisted functionalities, such as snippet transforms and snippet discovery\n\nThe interruption is tied to unexpected issues with specific cloud services, and we are also actively investigating the possibility of a cyber-related incident as part of our root cause analysis.\n\nWe want to reassure all users that your data security and privacy are not impacted. As a precaution, our security and infrastructure teams are treating this with the highest level of urgency and diligence. We are taking all necessary steps to investigate and remediate the issue.\n\nOur engineering and security teams are working around the clock to restore full functionality. We\u2019ll continue to provide updates in this thread as we learn more and make progress.\n\nYou can track the status of this interruption here and we\u2019ll notify you once normal service has resumed.\n\nWe deeply appreciate your patience and understanding during this time. If you have urgent concerns or need support, please reach out via our usual support channels.\n\nThe Pieces Team\nNo comments found on this issue.",
          "activity_level": 2.15
        },
        {
          "id": 755,
          "title": "Pieces has become increasingly slow and is now unresponsive",
          "text": "Pieces has become increasingly slow and is now unresponsive\n### Checked for Existing Issues?\n\n- [x] Yes, I have checked existing issues and cannot find one related to this.\n\n### Software\n\nDesktop Application\n\n### Operating System / Platform\n\nmacOS\n\n### Your Pieces OS Version\n\nVersion 4.2.0 (4.2.0)\n\n### Early Access Program\n\n- [ ] Yes, this is related to an Early Access Program feature.\n\n### Kindly describe the bug and include as much detail as possible on what you were doing so we can reproduce the bug.\n\nI have been using Pieces for many months and it has been an absolute timesaver. \n\nOver the last few weeks, 'New chats' have become increasingly slow, often taking many minutes to get the first response.  This week, it is not responding at all, and failing with the error message: \n\"I'm sorry. Something went wrong with processing. Please wait a few seconds and try again, or contact support@pieces.app\"\n\nI have attempted this with and without LTM enabled and have tried different LLM models - Claude 3.7 Sonnet, Clause 3.5 Sonnect, GPT-4o.    This has not resolved things.\n\nI have independently run the same request with GPT-4o in the browser and the request response is very rapid, so the issue appears to be with the Pieces App, rather than with the LLM\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 5.03
        },
        {
          "id": 759,
          "title": "Can't login/authentication message won't arrive",
          "text": "Can't login/authentication message won't arrive\n### Checked for Existing Issues?\n\n- [x] Yes, I have checked existing issues and cannot find one related to this.\n\n### Software\n\nDesktop Application\n\n### Operating System / Platform\n\nmacOS\n\n### Your Pieces OS Version\n\n12.0.0\n\n### Early Access Program\n\n- [ ] Yes, this is related to an Early Access Program feature.\n\n### Kindly describe the bug and include as much detail as possible on what you were doing so we can reproduce the bug.\n\nI haven't been online a lot because of personal issues. Yesterday I restarted pieces for the first time in weeks, and it said I needed to sign in before I can continue.\nFirst the sign in link wouldn't work. Then I noticed there was a Pieces OS update too. After I clicked that update I got back to the same screen and the link would work.\nSo I entered my mail address and it said I should get a verification code, which never arrived. So I tried again later and still nothing happened. I decided to let it rest until today and try it again, but still the same result.\n\nAlso, please allow people to continue offline if you can't get your online authentication to work properly.\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 4.42
        }
      ]
    },
    {
      "title": "Workstream activities tab sync issues and download cancellation problems",
      "description": "Users are experiencing issues with the Workstream activities tab not syncing correctly after updates, showing outdated activity times. Additionally, there are reports of being unable to cancel LLLM downloads, with the cancel button not functioning as expected.  Further investigation is needed to determine the root cause and potential solutions for both issues. This may involve checking server-side logs, network connectivity, and download management processes.",
      "frequency": 3,
      "related_issues": [
        {
          "id": 753,
          "title": "Workstream activities tab is not working",
          "text": "Workstream activities tab is not working\n### Checked for Existing Issues?\n\n- [x] Yes, I have checked existing issues and cannot find one related to this.\n\n### Software\n\nDesktop Application\n\n### Operating System / Platform\n\nmacOS\n\n### Your Pieces OS Version\n\n12.0.0\n\n### Early Access Program\n\n- [ ] Yes, this is related to an Early Access Program feature.\n\n### Kindly describe the bug and include as much detail as possible on what you were doing so we can reproduce the bug.\n\nI faced a sync problem, Can you check it please?\n\nAfter the update, My activities wasn't updated.\nIt's 11pm but activities updated until 5am.\nI used my computer for 0~5am and 7~11pm\n\n![Image](https://github.com/user-attachments/assets/a22b6811-2841-4eb7-b214-36bf4528b702)\n\nI think it can be same with #751 \nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 2.71
        },
        {
          "id": 751,
          "title": "Unable to generate Workstream Summary",
          "text": "Unable to generate Workstream Summary\nError: ApiException 400: HTTP connection failed: POST /workstream_summaries/create/summary (Inner exception: ClientException: Connection closed before full header was received, uri=http://127.0.0.1:39300/workstream_summaries/create/summary)\n\n*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\npid: 360, tid: 6111358976, name io.flutter.ui\nos: macos arch: arm64 comp: no sim: no\nbuild_id: '07f8dd5e45c034b482654a241a0e541e'\nisolate_dso_base: 112b9c000, vm_dso_base: 112b9c000\nisolate_instructions: 112ba9300, vm_instructions: 112b9ea40\n    #00 abs 00000001136eecdb _kDartIsolateSnapshotInstructions+0xb459db\n<asynchronous suspension>\n    #01 abs 0000000113607bef _kDartIsolateSnapshotInstructions+0xa5e8ef\n<asynchronous suspension>\n    #02 abs 000000011364bf87 _kDartIsolateSnapshotInstructions+0xaa2c87\n<asynchronous suspension>\n    #03 abs 000000011364bc0b _kDartIsolateSnapshotInstructions+0xaa290b\n<asynchronous suspension>\n\n\n**Installation Details**\n\nSucceeded: true\nPath: /Applications/Pieces OS.app/Contents/MacOS/Pieces OS\n\n**PiecesOS Information**\n\nID: AA6F5C12-2751-486A-B846-7C6091C6C59D\nUser: 03415321-da89-4fb5-a694-576033517aa5\nCurrent Version: 12.0.0\nMin Version Supported: 12.0.0\nMax Version Supported: 13.0.0\nLocal Port: 39300\n\n**Device Information**\n\nOperating System: MacOS\nCurrent Version: Version 15.2 (Build 24C101)\nMin Version Supported: 12.0.0 Monterey\nAdditional Device Information: {cpu_list: [{\"architecture\":\"arm64\",\"cores\":4,\"logicalProcessors\":4,\"l1Cache\":{\"value\":131072,\"units\":\"Bytes\"},\"l2Cache\":{\"value\":16777216,\"units\":\"Bytes\"},\"description\":\"Apple M4\"}], gpu_list: [], memory_info: {\"totalRAM\":{\"value\":8589934592,\"units\":\"Bytes\"}}, display_list: [{\"nativeHeight\":3086,\"nativeWidth\":5984,\"scaledHeight\":1543,\"scaledWidth\":2992,\"primary\":true}]}\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 5.61
        },
        {
          "id": 459,
          "title": "Bug: unable to cancel the download of an LLLM",
          "text": "Bug: unable to cancel the download of an LLLM\n### Software\n\nDesktop Application\n\n### Operating System / Platform\n\nWindows\n\n### Your Pieces OS Version\n\nlatest\n\n### Early Access Program\n\n- [ ] Yes, this is related to an Early Access Program feature.\n\n### Kindly describe the bug and include as much detail as possible on what you were doing so we can reproduce the bug.\n\n![image](https://github.com/user-attachments/assets/6e730898-a168-4571-ab0d-6331c4d389a4)\r\n\r\ni want stop but its not working \r\n\nError generating summary: 404 Publisher Model `projects/pi3c3s-cloud-server/locations/us-east1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
          "activity_level": 2.64
        }
      ]
    }
  ],
  "recommendations": [
    "Investigate and resolve the \"Failed to extract context\" error in the `ask_pieces_ltm` MCP tool. This appears to be a recurring issue affecting multiple users.",
    "Address the performance issues in the Pieces desktop app on macOS. Users are reporting slowdowns and unresponsiveness, which hinders their workflow.",
    "Investigate and fix the login issues on macOS where users are not receiving verification codes. This prevents users from accessing the app.",
    "Address the issue on Linux where the desktop app fails to initialize after the latest update. This completely blocks users on Linux from using Pieces.",
    "Investigate and resolve the LTM-2.5 activation failures during onboarding. TimeoutExceptions are preventing users from enabling LTM.",
    "Fix the issue with generating workstream summaries, which is failing due to HTTP connection errors. This impacts users' ability to review their activity.",
    "Address the problem with the Workstream activities tab not syncing correctly after updates. This leads to inaccurate activity information.",
    "Fix the bug preventing users from canceling LLLM downloads. The non-functional cancel button creates a frustrating user experience.",
    "Monitor and address the ongoing cloud service interruption affecting Copilot, Workstream summaries, snippet transforms, and snippet discovery. Keep users informed about the progress of the investigation and restoration efforts.",
    "Prioritize these issues based on their frequency, activity level, and potential impact on users. Allocate resources accordingly to ensure timely resolution and improve user satisfaction.",
    "Improve communication with users regarding ongoing issues and their resolution status. Provide regular updates and transparent information to manage expectations and maintain trust.",
    "Enhance error logging and reporting mechanisms to gather more detailed information about issues, facilitating faster debugging and resolution.",
    "Implement automated testing and monitoring to catch issues early and prevent regressions. This will improve the overall stability and reliability of the Pieces platform.",
    "Collect user feedback on specific issues and pain points to better understand their impact and prioritize development efforts.",
    "Consider providing temporary workarounds or alternative solutions for affected users while permanent fixes are being developed.",
    "Review and optimize the onboarding process, particularly the LTM activation steps, to ensure a smooth and error-free experience for new users.",
    "Investigate potential resource conflicts or bottlenecks that may be contributing to performance issues, especially on macOS and with LTM-2.5 enabled.",
    "Analyze the download management process for LLLMs to identify the root cause of the cancellation bug and implement a robust solution.",
    "Review and update the documentation and support resources to address common issues and provide clear guidance to users.",
    "Proactively monitor system performance and user activity to identify potential issues before they escalate and impact a larger user base.",
    "Establish a clear escalation path for critical issues to ensure rapid response and resolution by the appropriate teams.",
    "Conduct thorough root cause analysis for recurring issues to prevent them from reoccurring in the future.",
    "Implement a system for tracking and prioritizing bug fixes and feature requests based on user impact and business needs.",
    "Regularly review and update support processes and tools to improve efficiency and effectiveness.",
    "Provide training and resources to support staff to equip them with the knowledge and skills to handle user inquiries effectively.",
    "Foster a culture of continuous improvement in support operations by encouraging feedback, innovation, and collaboration.",
    "Measure and track key support metrics, such as resolution time, customer satisfaction, and ticket volume, to identify areas for improvement and monitor progress.",
    "Communicate support performance and key learnings to stakeholders to ensure alignment and transparency.",
    "Collaborate with other teams, such as development and product management, to address systemic issues and improve the overall user experience.",
    "Stay informed about industry best practices and emerging trends in support operations to identify opportunities for innovation and improvement.",
    "Encourage users to report issues and provide feedback through multiple channels, such as in-app feedback forms, community forums, and social media.",
    "Analyze user feedback and support data to identify common themes and trends, which can inform product development and support strategies.",
    "Develop a knowledge base or FAQ section to address frequently asked questions and provide self-service support options to users.",
    "Consider implementing a chatbot or virtual assistant to handle basic inquiries and triage support requests.",
    "Personalize support interactions to create a positive user experience and build rapport with customers.",
    "Empower support staff to make decisions and resolve issues independently, reducing resolution time and improving customer satisfaction.",
    "Regularly review and update support documentation and training materials to ensure they are accurate and up-to-date.",
    "Conduct regular surveys or feedback sessions to gather input from users on their support experience and identify areas for improvement.",
    "Recognize and reward support staff for their contributions to create a positive and motivating work environment.",
    "Promote a culture of customer-centricity within the support team to ensure that user needs are always prioritized.",
    "Continuously evaluate and refine support processes and tools to optimize efficiency and effectiveness.",
    "Leverage automation and AI-powered tools to streamline support workflows and improve response times.",
    "Invest in training and development programs to enhance the skills and knowledge of support staff.",
    "Foster a collaborative environment within the support team to encourage knowledge sharing and problem-solving.",
    "Establish clear service level agreements (SLAs) for different types of support requests to manage user expectations and ensure timely resolution.",
    "Track and analyze support metrics to identify trends, measure performance, and drive continuous improvement.",
    "Communicate regularly with stakeholders about support performance, key challenges, and improvement initiatives.",
    "Stay up-to-date on industry best practices and emerging technologies in customer support to identify opportunities for innovation.",
    "Encourage users to provide feedback on their support experience to identify areas for improvement and enhance customer satisfaction.",
    "Develop a comprehensive support strategy that aligns with business goals and user needs.",
    "Build a strong support team with the right skills, knowledge, and attitude to provide excellent customer service.",
    "Create a positive and supportive work environment for the support team to foster motivation and engagement.",
    "Continuously evaluate and improve support processes and tools to optimize efficiency and effectiveness.",
    "Leverage technology and automation to streamline support workflows and enhance productivity.",
    "Measure and track key support metrics to monitor performance and identify areas for improvement.",
    "Communicate effectively with users and stakeholders to keep them informed and manage expectations.",
    "Stay informed about industry trends and best practices to ensure the support team is providing the best possible service.",
    "Foster a culture of customer-centricity within the support team to prioritize user needs and satisfaction.",
    "Empower support staff to make decisions and resolve issues independently, promoting efficiency and ownership.",
    "Provide regular training and development opportunities to enhance the skills and knowledge of support staff.",
    "Encourage feedback and collaboration within the support team to foster continuous improvement and innovation.",
    "Build strong relationships with other teams, such as development and product management, to address systemic issues and improve the overall user experience.",
    "Proactively identify and address potential support challenges before they escalate and impact users.",
    "Develop a knowledge base and self-service resources to empower users to find solutions to common issues independently.",
    "Implement a robust ticketing system to track and manage support requests efficiently.",
    "Utilize customer relationship management (CRM) tools to manage user interactions and personalize support experiences.",
    "Leverage analytics and reporting tools to gain insights into support performance and identify areas for improvement.",
    "Communicate support performance and key learnings to stakeholders to ensure transparency and alignment.",
    "Stay informed about industry best practices and emerging technologies to continuously improve support operations.",
    "Encourage user feedback and actively solicit suggestions for improvement to enhance the overall support experience.",
    "Prioritize user needs and satisfaction in all support interactions to build strong customer relationships and loyalty.",
    "Continuously evaluate and refine support processes and tools to optimize efficiency and effectiveness.",
    "Invest in the development and training of support staff to ensure they have the skills and knowledge to provide excellent service.",
    "Foster a culture of collaboration and innovation within the support team to drive continuous improvement.",
    "Measure and track key support metrics to monitor performance and identify areas for optimization.",
    "Communicate effectively with users and stakeholders to manage expectations and build trust.",
    "Stay informed about industry trends and best practices to ensure the support team is providing the best possible service.",
    "Empower support staff to make decisions and resolve issues independently, promoting efficiency and ownership.",
    "Develop a comprehensive support strategy that aligns with business goals and user needs.",
    "Build a strong support team with the right skills, knowledge, and attitude to provide exceptional customer service.",
    "Create a positive and supportive work environment for the support team to foster motivation and engagement.",
    "Continuously evaluate and improve support processes and tools to optimize efficiency and effectiveness.",
    "Leverage technology and automation to streamline support workflows and enhance productivity.",
    "Measure and track key support metrics to monitor performance and identify areas for improvement.",
    "Communicate effectively with users and stakeholders to keep them informed and manage expectations.",
    "Stay informed about industry trends and best practices to ensure the support team is providing the best possible service.",
    "Foster a culture of customer-centricity within the support team to prioritize user needs and satisfaction.",
    "Empower support staff to make decisions and resolve issues independently, promoting efficiency and ownership.",
    "Provide regular training and development opportunities to enhance the skills and knowledge of support staff.",
    "Encourage feedback and collaboration within the support team to foster continuous improvement and innovation.",
    "Build strong relationships with other teams, such as development and product management, to address systemic issues and improve the overall user experience.",
    "Proactively identify and address potential support challenges before they escalate and impact users.",
    "Develop a knowledge base and self-service resources to empower users to find solutions to common issues independently.",
    "Implement a robust ticketing system to track and manage support requests efficiently.",
    "Utilize customer relationship management (CRM) tools to manage user interactions and personalize support experiences.",
    "Leverage analytics and reporting tools to gain insights into support performance and identify areas for improvement.",
    "Communicate support performance and key learnings to stakeholders to ensure transparency and alignment.",
    "Stay informed about industry best practices and emerging technologies to continuously improve support operations.",
    "Encourage user feedback and actively solicit suggestions for improvement to enhance the overall support experience.",
    "Prioritize user needs and satisfaction in all support interactions to build strong customer relationships and loyalty.",
    "Continuously evaluate and refine support processes and tools to optimize efficiency and effectiveness.",
    "Invest in the development and training of support staff to ensure they have the skills and knowledge to provide excellent service.",
    "Foster a culture of collaboration and innovation within the support team to drive continuous improvement.",
    "Measure and track key support metrics to monitor performance and identify areas for optimization.",
    "Communicate effectively with users and stakeholders to manage expectations and build trust.",
    "Stay informed about industry trends and best practices to ensure the support team is providing the best possible service.",
    "Empower support staff to make decisions and resolve issues independently, promoting efficiency and ownership.",
    "Resolve cloud service interruption and ensure data security is not impacted by the cyber-related incident being investigated."
  ],
  "message": "Daily support report generated successfully."
}